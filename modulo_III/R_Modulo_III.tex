\documentclass[10pt]{beamer}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\usetheme[compress]{PaloAlto}
\usecolortheme{sidebartab}
%\logo{\includegraphics[width=1cm]{../Rlogo-5.png}}

\usepackage[brazilian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[normalem]{ulem}
\usepackage{paralist}
\usepackage{xfrac}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage[scaled]{beramono} % truetype: Bistream Vera Sans Mono
%\usepackage{inconsolata}

\setbeamertemplate{footline}[frame number] % mostra o numero dos slides
\setbeamertemplate{navigation symbols}{} % retira a barra de navegacao

\usepackage{xspace}
\providecommand{\eg}{\textit{e.g.}\xspace}
\providecommand{\ie}{\textit{i.e.}\xspace}
\providecommand{\R}{\textsf{R}\xspace}
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\providecommand{\E}{\text{E}}
\providecommand{\Var}{\text{Var}}
\providecommand{\DP}{\text{DP}}
\theoremstyle{definition}
\newtheorem*{mydef}{Definição}
\newtheorem*{mythm}{Teorema}



\title[Módulo III\\ Inferência e Modelagem]{Introdução ao uso do software R}
\author[IMEF 2014]{Fernando de Pol Mayer\inst{1} \and %\url{fernandomayer@gmail.com} \and
Rodrigo Sant'Ana\inst{2}} %\\ \url{oc.rodrigosantana@gmail.com}}
\date{}
\institute{
  \inst{1}%
  Laboratório de Estatística Ambiental (LEA) \\
  Instituto de Matemática, Estatística e Física (IMEF) \\
  Universidade Federal do Rio Grande (FURG) \\
  \url{fernando.mayer@furg.br}
  \and
  \inst{2}%
  Instituto Albatroz \\
  \url{oc.rodrigosantana@gmail.com}
}
\logo{\includegraphics[width=1cm]{../conf/Rlogo-5}}

\AtBeginSection[]
{
  \begin{frame}
    \frametitle{Sumário}
    \tableofcontents[currentsection]
  \end{frame}
}

\AtBeginSubsection[]
{
  \begin{frame}
    \frametitle{Sumário}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}



\begin{frame}
\maketitle
%\titlepage
\end{frame}

\begin{frame}{Sumário}
\tableofcontents
\end{frame}

\section{Distribuições de probabilidade}

\begin{frame}[fragile=singleslide]{Distribuições de probabilidade}
A maioria das distribuições de probabilidade tradicionais estão
implementadas no R, e podem ser utilizadas para substituir as tabelas
estatísticas tradicionais. Existem 4 itens fundamentais que podem ser
calculados para cada distribuição:
\vspace{1em}
\begin{itemize}
\item[d*] Calcula a densidade de probabilidade ou probabilidade pontual
\item[p*] Calcula a função de probabilidade acumulada
\item[q*] Calcula o quantil correspondente a uma dada probabilidade
\item[r*] Gera números aleatórios (ou ``pseudo-aleatórios'')
\end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Distribuições de probabilidade}
As distribuições de probabilidade mais comuns são:
\begin{center}
% use packages: array
\begin{tabular}{lll}
\hline
Distribuição & Nome no \R      & Parâmetros          \\
\hline
Binomial     & \texttt{*binom} & \texttt{size, prob} \\
$\chi^2$     & \texttt{*chisq} & \texttt{df}         \\

Normal & \texttt{*norm} & \texttt{mean, sd}                  \\
Poisson                 & \texttt{*pois} & \texttt{lambda}   \\
t                       & \texttt{*t}    & \texttt{df}       \\
Uniforme                & \texttt{*unif} & \texttt{min, max} \\
\hline
\end{tabular}
\end{center}
\end{frame}

\begin{frame}[fragile=singleslide]{Distribuições de probabilidade}
Alguns exemplos:
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# valores críticos de z com alfa = 0,05 (bilateral)}
\hlkwd{qnorm}\hlstd{(}\hlnum{0.025}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] -1.959964
\end{verbatim}
\begin{alltt}
\hlkwd{qnorm}\hlstd{(}\hlnum{0.975}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] 1.959964
\end{verbatim}
\begin{alltt}
\hlcom{# valores críticos de t com diferentes G.L.}
\hlkwd{qt}\hlstd{(}\hlnum{0.025}\hlstd{,} \hlkwc{df} \hlstd{=} \hlnum{9}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] -2.262157
\end{verbatim}
\begin{alltt}
\hlkwd{qt}\hlstd{(}\hlnum{0.025}\hlstd{,}\hlkwc{df} \hlstd{=} \hlnum{900}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] -1.962603
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Distribuições de probabilidade}
Intervalos de confiança: suponha uma amostra de $n=5$, com $\bar{x}=83$
e $s=12$. Um intervalo de 95\% de confiança ($\alpha = 0.05$) para $\mu$
pode ser calculado como:
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Dados}
\hlstd{xbarra} \hlkwb{<-} \hlnum{83}
\hlstd{desvio} \hlkwb{<-} \hlnum{12}
\hlstd{n} \hlkwb{<-} \hlnum{5}
\hlcom{## Erro padrão}
\hlstd{erro} \hlkwb{<-} \hlstd{desvio}\hlopt{/}\hlkwd{sqrt}\hlstd{(n)}
\hlcom{## Média - erro}
\hlstd{xbarra} \hlopt{+} \hlstd{erro} \hlopt{*} \hlkwd{qt}\hlstd{(}\hlnum{0.025}\hlstd{,} \hlkwc{df} \hlstd{= n)}
\end{alltt}
\begin{verbatim}
[1] 69.20481
\end{verbatim}
\begin{alltt}
\hlcom{## Média + erro}
\hlstd{xbarra} \hlopt{+} \hlstd{erro} \hlopt{*} \hlkwd{qt}\hlstd{(}\hlnum{0.975}\hlstd{,} \hlkwc{df} \hlstd{= n)}
\end{alltt}
\begin{verbatim}
[1] 96.79519
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Modelo Bernoulli}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{1}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.2}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] 0.8 0.2
\end{verbatim}
\begin{alltt}
\hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{1}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.5}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] 0.5 0.5
\end{verbatim}
\begin{alltt}
\hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{1}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.7}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] 0.3 0.7
\end{verbatim}
\begin{alltt}
\hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{1}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.9}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] 0.1 0.9
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Modelo Bernoulli}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{par}\hlstd{(}\hlkwc{mfrow}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{2}\hlstd{,}\hlnum{2}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,} \hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{1}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.2}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"h"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"P[X = x]"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlstr{"p = 0.2"}\hlstd{,}
     \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,} \hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{1}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.5}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"h"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"P[X = x]"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlstr{"p = 0.5"}\hlstd{,}
     \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,} \hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{1}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.7}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"h"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"P[X = x]"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlstr{"p = 0.7"}\hlstd{,}
     \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,} \hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{1}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{1}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.9}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"h"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"P[X = x]"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlstr{"p = 0.9"}\hlstd{,}
     \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Modelo Bernoulli}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-5-1} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Modelo binomial}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{5}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{5}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.2}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] 0.32768 0.40960 0.20480 0.05120 0.00640 0.00032
\end{verbatim}
\begin{alltt}
\hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{5}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{5}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.5}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] 0.03125 0.15625 0.31250 0.31250 0.15625 0.03125
\end{verbatim}
\begin{alltt}
\hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{5}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{5}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.7}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] 0.00243 0.02835 0.13230 0.30870 0.36015 0.16807
\end{verbatim}
\begin{alltt}
\hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{5}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{5}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.9}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] 0.00001 0.00045 0.00810 0.07290 0.32805 0.59049
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Modelo binomial}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{par}\hlstd{(}\hlkwc{mfrow}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{2}\hlstd{,}\hlnum{2}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{10}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.2}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"h"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"P[X = x]"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlstr{"n = 10, p = 0.2"}\hlstd{,}
     \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{.5}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{10}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.5}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"h"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"P[X = x]"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlstr{"n = 10, p = 0.5"}\hlstd{,}
     \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{.5}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{10}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.7}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"h"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"P[X = x]"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlstr{"n = 10, p = 0.7"}\hlstd{,}
     \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{.5}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwd{dbinom}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{10}\hlstd{,} \hlkwc{prob} \hlstd{=} \hlnum{.9}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"h"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"P[X = x]"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlstr{"n = 10, p = 0.9"}\hlstd{,}
     \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{.5}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Modelo binomial}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-8-1} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Modelo Poisson}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{dpois}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwc{lambda} \hlstd{=} \hlnum{1}\hlstd{)}
\end{alltt}
\begin{verbatim}
 [1] 3.678794e-01 3.678794e-01 1.839397e-01 6.131324e-02
 [5] 1.532831e-02 3.065662e-03 5.109437e-04 7.299195e-05
 [9] 9.123994e-06 1.013777e-06 1.013777e-07
\end{verbatim}
\begin{alltt}
\hlkwd{dpois}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwc{lambda} \hlstd{=} \hlnum{5}\hlstd{)}
\end{alltt}
\begin{verbatim}
 [1] 0.006737947 0.033689735 0.084224337 0.140373896 0.175467370
 [6] 0.175467370 0.146222808 0.104444863 0.065278039 0.036265577
[11] 0.018132789
\end{verbatim}
\begin{alltt}
\hlkwd{dpois}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwc{lambda} \hlstd{=} \hlnum{10}\hlstd{)}
\end{alltt}
\begin{verbatim}
 [1] 4.539993e-05 4.539993e-04 2.269996e-03 7.566655e-03
 [5] 1.891664e-02 3.783327e-02 6.305546e-02 9.007923e-02
 [9] 1.125990e-01 1.251100e-01 1.251100e-01
\end{verbatim}
\begin{alltt}
\hlkwd{dpois}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{10}\hlstd{,} \hlkwc{lambda} \hlstd{=} \hlnum{15}\hlstd{)}
\end{alltt}
\begin{verbatim}
 [1] 3.059023e-07 4.588535e-06 3.441401e-05 1.720701e-04
 [5] 6.452627e-04 1.935788e-03 4.839470e-03 1.037029e-02
 [9] 1.944430e-02 3.240717e-02 4.861075e-02
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Modelo Poisson}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{par}\hlstd{(}\hlkwc{mfrow}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{2}\hlstd{,}\hlnum{2}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{30}\hlstd{,} \hlkwd{dpois}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{30}\hlstd{,} \hlkwc{lambda} \hlstd{=} \hlnum{1}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"h"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"P[X = x]"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlkwd{expression}\hlstd{(mu} \hlopt{==} \hlnum{1}\hlstd{),}
     \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{.4}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{30}\hlstd{,} \hlkwd{dpois}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{30}\hlstd{,} \hlkwc{lambda} \hlstd{=} \hlnum{5}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"h"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"P[X = x]"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlkwd{expression}\hlstd{(mu} \hlopt{==} \hlnum{5}\hlstd{),}
     \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{.4}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{30}\hlstd{,} \hlkwd{dpois}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{30}\hlstd{,} \hlkwc{lambda} \hlstd{=} \hlnum{10}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"h"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"P[X = x]"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlkwd{expression}\hlstd{(mu} \hlopt{==} \hlnum{10}\hlstd{),}
     \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{.4}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlnum{0}\hlopt{:}\hlnum{30}\hlstd{,} \hlkwd{dpois}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{0}\hlopt{:}\hlnum{30}\hlstd{,} \hlkwc{lambda} \hlstd{=} \hlnum{15}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"h"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"P[X = x]"}\hlstd{,} \hlkwc{main} \hlstd{=} \hlkwd{expression}\hlstd{(mu} \hlopt{==} \hlnum{15}\hlstd{),}
     \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{.4}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Modelo Poisson}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-11-1} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Modelo normal}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{dnorm}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{40}\hlopt{:}\hlnum{60}\hlstd{,} \hlkwc{mean} \hlstd{=} \hlnum{50}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlnum{5}\hlstd{)}
\end{alltt}
\begin{verbatim}
 [1] 0.01079819 0.01579003 0.02218417 0.02994549 0.03883721
 [6] 0.04839414 0.05793831 0.06664492 0.07365403 0.07820854
[11] 0.07978846 0.07820854 0.07365403 0.06664492 0.05793831
[16] 0.04839414 0.03883721 0.02994549 0.02218417 0.01579003
[21] 0.01079819
\end{verbatim}
\begin{alltt}
\hlkwd{dnorm}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{40}\hlopt{:}\hlnum{60}\hlstd{,} \hlkwc{mean} \hlstd{=} \hlnum{50}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlnum{10}\hlstd{)}
\end{alltt}
\begin{verbatim}
 [1] 0.02419707 0.02660852 0.02896916 0.03122539 0.03332246
 [6] 0.03520653 0.03682701 0.03813878 0.03910427 0.03969525
[11] 0.03989423 0.03969525 0.03910427 0.03813878 0.03682701
[16] 0.03520653 0.03332246 0.03122539 0.02896916 0.02660852
[21] 0.02419707
\end{verbatim}
\begin{alltt}
\hlkwd{dnorm}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{90}\hlopt{:}\hlnum{110}\hlstd{,} \hlkwc{mean} \hlstd{=} \hlnum{100}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlnum{5}\hlstd{)}
\end{alltt}
\begin{verbatim}
 [1] 0.01079819 0.01579003 0.02218417 0.02994549 0.03883721
 [6] 0.04839414 0.05793831 0.06664492 0.07365403 0.07820854
[11] 0.07978846 0.07820854 0.07365403 0.06664492 0.05793831
[16] 0.04839414 0.03883721 0.02994549 0.02218417 0.01579003
[21] 0.01079819
\end{verbatim}
\begin{alltt}
\hlkwd{dnorm}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{190}\hlopt{:}\hlnum{210}\hlstd{,} \hlkwc{mean} \hlstd{=} \hlnum{200}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlnum{5}\hlstd{)}
\end{alltt}
\begin{verbatim}
 [1] 0.01079819 0.01579003 0.02218417 0.02994549 0.03883721
 [6] 0.04839414 0.05793831 0.06664492 0.07365403 0.07820854
[11] 0.07978846 0.07820854 0.07365403 0.06664492 0.05793831
[16] 0.04839414 0.03883721 0.02994549 0.02218417 0.01579003
[21] 0.01079819
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Modelo normal}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{par}\hlstd{(}\hlkwc{mfrow}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{2}\hlstd{,}\hlnum{2}\hlstd{))}
\hlkwd{plot}\hlstd{(}\hlkwd{seq}\hlstd{(}\hlnum{10}\hlstd{,} \hlnum{90}\hlstd{,} \hlkwc{length}\hlstd{=}\hlnum{100}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"l"}\hlstd{,} \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"f(x)"}\hlstd{,}
     \hlkwc{y} \hlstd{=} \hlkwd{dnorm}\hlstd{(}\hlkwc{x} \hlstd{=} \hlkwd{seq}\hlstd{(}\hlnum{10}\hlstd{,} \hlnum{90}\hlstd{,} \hlkwc{length}\hlstd{=}\hlnum{100}\hlstd{),} \hlkwc{mean} \hlstd{=} \hlnum{50}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlnum{5}\hlstd{),}
     \hlkwc{main} \hlstd{=} \hlkwd{expression}\hlstd{(}\hlkwd{list}\hlstd{(mu} \hlopt{==} \hlnum{50}\hlstd{, sigma}\hlopt{^}\hlnum{2} \hlopt{==} \hlnum{25}\hlstd{)))}
\hlkwd{plot}\hlstd{(}\hlkwd{seq}\hlstd{(}\hlnum{10}\hlstd{,} \hlnum{90}\hlstd{,} \hlkwc{length}\hlstd{=}\hlnum{100}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"l"}\hlstd{,} \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"f(x)"}\hlstd{,}
     \hlkwc{y} \hlstd{=} \hlkwd{dnorm}\hlstd{(}\hlkwc{x} \hlstd{=} \hlkwd{seq}\hlstd{(}\hlnum{10}\hlstd{,} \hlnum{90}\hlstd{,} \hlkwc{length}\hlstd{=}\hlnum{100}\hlstd{),} \hlkwc{mean} \hlstd{=} \hlnum{50}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlnum{10}\hlstd{),}
     \hlkwc{main} \hlstd{=} \hlkwd{expression}\hlstd{(}\hlkwd{list}\hlstd{(mu} \hlopt{==} \hlnum{50}\hlstd{, sigma}\hlopt{^}\hlnum{2} \hlopt{==} \hlnum{100}\hlstd{)))}
\hlkwd{plot}\hlstd{(}\hlkwd{seq}\hlstd{(}\hlnum{70}\hlstd{,} \hlnum{130}\hlstd{,} \hlkwc{length}\hlstd{=}\hlnum{100}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"l"}\hlstd{,} \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"f(x)"}\hlstd{,}
     \hlkwc{y} \hlstd{=} \hlkwd{dnorm}\hlstd{(}\hlkwc{x} \hlstd{=} \hlkwd{seq}\hlstd{(}\hlnum{70}\hlstd{,} \hlnum{130}\hlstd{,} \hlkwc{length}\hlstd{=}\hlnum{100}\hlstd{),} \hlkwc{mean} \hlstd{=} \hlnum{100}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlnum{5}\hlstd{),}
     \hlkwc{main} \hlstd{=} \hlkwd{expression}\hlstd{(}\hlkwd{list}\hlstd{(mu} \hlopt{==} \hlnum{100}\hlstd{, sigma}\hlopt{^}\hlnum{2} \hlopt{==} \hlnum{25}\hlstd{)))}
\hlkwd{plot}\hlstd{(}\hlkwd{seq}\hlstd{(}\hlnum{170}\hlstd{,} \hlnum{230}\hlstd{,} \hlkwc{length}\hlstd{=}\hlnum{100}\hlstd{),} \hlkwc{type} \hlstd{=} \hlstr{"l"}\hlstd{,} \hlkwc{xlab} \hlstd{=} \hlstr{"X"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"f(x)"}\hlstd{,}
     \hlkwc{y} \hlstd{=} \hlkwd{dnorm}\hlstd{(}\hlkwc{x} \hlstd{=} \hlkwd{seq}\hlstd{(}\hlnum{170}\hlstd{,} \hlnum{230}\hlstd{,} \hlkwc{length}\hlstd{=}\hlnum{100}\hlstd{),} \hlkwc{mean} \hlstd{=} \hlnum{200}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlnum{5}\hlstd{),}
     \hlkwc{main} \hlstd{=} \hlkwd{expression}\hlstd{(}\hlkwd{list}\hlstd{(mu} \hlopt{==} \hlnum{200}\hlstd{, sigma}\hlopt{^}\hlnum{2} \hlopt{==} \hlnum{25}\hlstd{)))}
\hlkwd{par}\hlstd{(}\hlkwc{mfrow}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,}\hlnum{1}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Modelo normal}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-14-1} 

}



\end{knitrout}
\end{frame}

\section{Inferência}

\begin{frame}[fragile=singleslide]{Base de dados}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{dados} \hlkwb{<-} \hlkwd{read.table}\hlstd{(}\hlstr{"../dados/crabs.csv"}\hlstd{,} \hlkwc{header} \hlstd{= T,}
                    \hlkwc{sep} \hlstd{=} \hlstr{";"}\hlstd{,} \hlkwc{dec} \hlstd{=} \hlstr{","}\hlstd{)}
\hlkwd{str}\hlstd{(dados)}
\end{alltt}
\begin{verbatim}
'data.frame':	156 obs. of  7 variables:
 $ especie: Factor w/ 2 levels "azul","laranja": 1 1 1 1 1 1 1 1 1 1 ...
 $ sexo   : Factor w/ 2 levels "F","M": 2 2 2 2 2 2 2 2 2 2 ...
 $ FL     : num  8.1 8.8 9.2 9.6 10.8 11.6 11.8 12.3 12.6 12.8 ...
 $ RW     : num  6.7 7.7 7.8 7.9 9 9.1 10.5 11 10 10.9 ...
 $ CL     : num  16.1 18.1 19 20.1 23 24.5 25.2 26.8 27.7 27.4 ...
 $ CW     : num  19 20.8 22.4 23.1 26.5 28.4 29.3 31.5 31.7 31.5 ...
 $ BD     : num  7 7.4 7.7 8.2 9.8 10.4 10.3 11.4 11.4 11 ...
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t
    para uma amostra}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{hist}\hlstd{(dados}\hlopt{$}\hlstd{CL,} \hlkwc{main} \hlstd{=} \hlstr{""}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"Frequência absoluta"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"Comprimento da carapaça (mm)"}\hlstd{,} \hlkwc{col} \hlstd{=} \hlstr{"grey"}\hlstd{)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=.6\textwidth]{figure/unnamed-chunk-16-1} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t
    para uma amostra}
Procedimentos gerais para um teste de hipótese
\begin{compactenum}[(1)]
\item Definir a hipótese nula ($H_0$) e a alternativa ($H_1$)
\item Definir um nível de \textbf{significância} $\alpha$ (ex.: $\alpha
  = 0,05$), que irá determinar o nível de \textbf{confiança}
  $100(1-\alpha)\%$ do teste
\item Determinar a \textbf{região de rejeição} com base no nível de
  significância $\rightarrow$ $t_{crit}$
\item Calcula a \textbf{estatística de teste}, sob a hipótese nula
  \begin{equation*}
    t_{calc} = \frac{\bar{x} - \mu_0}{s/\sqrt{n}}
  \end{equation*}
\item Rejeitar a hipótese nula se a estatística de teste calculada
  estiver dentro da região de rejeição ($t_{calc} > t_{crit}$)
  \begin{itemize}
  \item Alternativamente, calcula-se o p-valor, que é a probabilidade de
    se obter um valor de $t$ igual ou maior do que $t_{calc}$
  \end{itemize}
\end{compactenum}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para uma
    amostra}
  \begin{itemize}
  \item Testar a hipótese de que a média ($\mu$) de CL é igual a 30 mm
    (com 95\% de confiança)
  \item As hipóteses são
    \begin{align*}
      H_0: \mu = 30 \\
      H_1: \mu \neq 30
    \end{align*}
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para uma
    amostra}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{t.test}\hlstd{(dados}\hlopt{$}\hlstd{CL,} \hlkwc{mu} \hlstd{=} \hlnum{30}\hlstd{,} \hlkwc{alternative} \hlstd{=} \hlstr{"two.sided"}\hlstd{,}
       \hlkwc{conf.level} \hlstd{=} \hlnum{0.95}\hlstd{)}
\end{alltt}
\begin{verbatim}

	One Sample t-test

data:  dados$CL
t = 3.4627, df = 155, p-value = 0.0006913
alternative hypothesis: true mean is not equal to 30
95 percent confidence interval:
 30.86071 33.14698
sample estimates:
mean of x 
 32.00385 
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para uma
    amostra}
  Fazendo manualmente
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## Dados}
\hlstd{xbarra} \hlkwb{<-} \hlkwd{mean}\hlstd{(dados}\hlopt{$}\hlstd{CL)}
\hlstd{mu0} \hlkwb{<-} \hlnum{30}
\hlstd{dp} \hlkwb{<-} \hlkwd{sd}\hlstd{(dados}\hlopt{$}\hlstd{CL)}
\hlstd{n} \hlkwb{<-} \hlkwd{nrow}\hlstd{(dados)}
\hlcom{# t calculado}
\hlstd{(tcalc} \hlkwb{<-} \hlstd{(xbarra} \hlopt{-} \hlstd{mu0)}\hlopt{/}\hlstd{(dp}\hlopt{/}\hlkwd{sqrt}\hlstd{(n)))}
\end{alltt}
\begin{verbatim}
[1] 3.462731
\end{verbatim}
\begin{alltt}
\hlcom{# t critico (não é apresentado no resultado)}
\hlkwd{qt}\hlstd{(}\hlnum{0.025}\hlstd{,} \hlkwc{df} \hlstd{= n} \hlopt{-} \hlnum{1}\hlstd{,} \hlkwc{lower.tail} \hlstd{=} \hlnum{FALSE}\hlstd{)}
\end{alltt}
\begin{verbatim}
[1] 1.975387
\end{verbatim}
\begin{alltt}
\hlcom{# valor p (multiplicado por 2 pois o teste é bilateral)}
\hlkwd{pt}\hlstd{(tcalc,} \hlkwc{df} \hlstd{= n} \hlopt{-} \hlnum{1}\hlstd{,} \hlkwc{lower.tail} \hlstd{=} \hlnum{FALSE}\hlstd{)} \hlopt{*} \hlnum{2}
\end{alltt}
\begin{verbatim}
[1] 0.000691346
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para uma
    amostra}
\textbf{Detalhe:} O teste pode ser armazenado em um objeto para futuras
referências
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{teste} \hlkwb{<-} \hlkwd{t.test}\hlstd{(dados}\hlopt{$}\hlstd{CL,} \hlkwc{mu} \hlstd{=} \hlnum{30}\hlstd{,} \hlkwc{alternative} \hlstd{=} \hlstr{"two.sided"}\hlstd{,}
                \hlkwc{conf.level} \hlstd{=} \hlnum{0.95}\hlstd{)}
\hlkwd{names}\hlstd{(teste)}
\end{alltt}
\begin{verbatim}
[1] "statistic"   "parameter"   "p.value"     "conf.int"   
[5] "estimate"    "null.value"  "alternative" "method"     
[9] "data.name"  
\end{verbatim}
\begin{alltt}
\hlstd{teste}\hlopt{$}\hlstd{statistic}
\end{alltt}
\begin{verbatim}
       t 
3.462731 
\end{verbatim}
\begin{alltt}
\hlstd{teste}\hlopt{$}\hlstd{p.value}
\end{alltt}
\begin{verbatim}
[1] 0.000691346
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para uma
    amostra}
  \begin{itemize}
  \item Testar a hipótese de que a média ($\mu$) de CL é menor ou igual
    a 30 mm (com 95\% de confiança)
  \item As hipóteses são
    \begin{align*}
      H_0: \mu \leq 30 \\
      H_1: \mu > 30
    \end{align*}
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para uma
    amostra}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{t.test}\hlstd{(dados}\hlopt{$}\hlstd{CL,} \hlkwc{mu} \hlstd{=} \hlnum{30}\hlstd{,} \hlkwc{alternative} \hlstd{=} \hlstr{"greater"}\hlstd{,}
       \hlkwc{conf.level} \hlstd{=} \hlnum{0.95}\hlstd{)}
\end{alltt}
\begin{verbatim}

	One Sample t-test

data:  dados$CL
t = 3.4627, df = 155, p-value = 0.0003457
alternative hypothesis: true mean is greater than 30
95 percent confidence interval:
 31.04626      Inf
sample estimates:
mean of x 
 32.00385 
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para uma
    amostra}
  \begin{itemize}
  \item Testar a hipótese de que a média ($\mu$) de CL é maior ou igual
    a 30 mm (com 95\% de confiança)
  \item As hipóteses são
    \begin{align*}
      H_0: \mu \geq 30 \\
      H_1: \mu < 30
    \end{align*}
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para uma
    amostra}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{t.test}\hlstd{(dados}\hlopt{$}\hlstd{CL,} \hlkwc{mu} \hlstd{=} \hlnum{30}\hlstd{,} \hlkwc{alternative} \hlstd{=} \hlstr{"less"}\hlstd{,}
       \hlkwc{conf.level} \hlstd{=} \hlnum{0.95}\hlstd{)}
\end{alltt}
\begin{verbatim}

	One Sample t-test

data:  dados$CL
t = 3.4627, df = 155, p-value = 0.9997
alternative hypothesis: true mean is less than 30
95 percent confidence interval:
     -Inf 32.96143
sample estimates:
mean of x 
 32.00385 
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Testes de hipótese}{Teste-t para duas amostras}
Faça dois histogramas lado-a-lado da medida CL para cada uma das
espécies.

\end{frame}

\begin{frame}[fragile]{Testes de hipótese}{Teste-t para duas amostras}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{par}\hlstd{(}\hlkwc{mfrow} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{))}
\hlkwd{hist}\hlstd{(dados}\hlopt{$}\hlstd{CL[dados}\hlopt{$}\hlstd{especie} \hlopt{==} \hlstr{"azul"}\hlstd{],} \hlkwc{main} \hlstd{=} \hlstr{"Azul"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"CL (mm)"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"Frequência"}\hlstd{,} \hlkwc{xlim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{10}\hlstd{,} \hlnum{50}\hlstd{))}
\hlkwd{hist}\hlstd{(dados}\hlopt{$}\hlstd{CL[dados}\hlopt{$}\hlstd{especie} \hlopt{==} \hlstr{"laranja"}\hlstd{],} \hlkwc{main} \hlstd{=} \hlstr{"Laranja"}\hlstd{,}
     \hlkwc{xlab} \hlstd{=} \hlstr{"CL (mm)"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"Frequência"}\hlstd{,} \hlkwc{xlim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{10}\hlstd{,} \hlnum{50}\hlstd{))}
\hlkwd{par}\hlstd{(}\hlkwc{mfrow} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,}\hlnum{1}\hlstd{))}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=.6\textwidth]{figure/unnamed-chunk-23-1} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para duas amostras}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{require}\hlstd{(lattice)} \hlcom{# pacote para gráficos avançados}
\hlkwd{histogram}\hlstd{(}\hlopt{~}\hlstd{CL} \hlopt{|} \hlstd{especie,} \hlkwc{data} \hlstd{= dados)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=.6\textwidth]{figure/unnamed-chunk-24-1} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para duas amostras}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{with}\hlstd{(dados,} \hlkwd{tapply}\hlstd{(CL, especie, summary))}
\end{alltt}
\begin{verbatim}
$azul
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  14.70   24.60   30.10   29.87   34.50   47.10 

$laranja
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  16.70   29.40   34.50   34.08   39.25   47.60 
\end{verbatim}
\end{kframe}
\end{knitrout}
Existem evidências de que uma espécie é maior do que a outra?
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para duas amostras}
  \begin{itemize}
  \item Testar a hipótese de que a \textbf{diferença} entre a média de
    CL da espécie azul ($\mu_A$) e a média de CL da espécie laranja
    ($\mu_L$) é igual a 0 (zero) (com 95\% de confiança)
  \item As hipóteses são
    \begin{align*}
      H_0: \mu_A - \mu_L = 0 \quad \Rightarrow \quad \mu_A = \mu_L \\
      H_1: \mu_A - \mu_L \neq 0 \quad \Rightarrow \quad \mu_A \neq \mu_L
    \end{align*}
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para duas amostras}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{t.test}\hlstd{(CL} \hlopt{~} \hlstd{especie,} \hlkwc{data} \hlstd{= dados,} \hlkwc{mu} \hlstd{=} \hlnum{0}\hlstd{,}
       \hlkwc{alternative} \hlstd{=} \hlstr{"two.sided"}\hlstd{,} \hlkwc{conf.level} \hlstd{=} \hlnum{0.95}\hlstd{)}
\end{alltt}
\begin{verbatim}

	Welch Two Sample t-test

data:  CL by especie
t = -3.7935, df = 152.732, p-value = 0.0002135
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -6.411592 -2.020366
sample estimates:
   mean in group azul mean in group laranja 
             29.86883              34.08481 
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para duas amostras}
  \begin{itemize}
  \item Testar a hipótese de que a \textbf{diferença} entre a média de
    CL da espécie azul ($\mu_A$) e a média de CL da espécie laranja
    ($\mu_L$) é \textbf{menor} ou iual a 0 (zero) (com 95\% de confiança)
  \item Em outras palavras: ``O CL médio é menor para a espécie azul?''
  \item As hipóteses são
    \begin{align*}
      H_0: \mu_A - \mu_L \leq 0 \quad \Rightarrow \quad \mu_A \leq \mu_L \\
      H_1: \mu_A - \mu_L > 0 \quad \Rightarrow \quad \mu_A > \mu_L
    \end{align*}
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Testes de hipótese}{Teste-t para duas amostras}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{t.test}\hlstd{(CL} \hlopt{~} \hlstd{especie,} \hlkwc{data} \hlstd{= dados,} \hlkwc{mu} \hlstd{=} \hlnum{0}\hlstd{,}
       \hlkwc{alternative} \hlstd{=} \hlstr{"greater"}\hlstd{,} \hlkwc{conf.level} \hlstd{=} \hlnum{0.95}\hlstd{)}
\end{alltt}
\begin{verbatim}

	Welch Two Sample t-test

data:  CL by especie
t = -3.7935, df = 152.732, p-value = 0.9999
alternative hypothesis: true difference in means is greater than 0
95 percent confidence interval:
 -6.055151       Inf
sample estimates:
   mean in group azul mean in group laranja 
             29.86883              34.08481 
\end{verbatim}
\end{kframe}
\end{knitrout}
Como você faria para calcular a diferença observada das médias de CL
entre as duas espécies?
\end{frame}

\begin{frame}[fragile=singleslide]{Exercícios}
Com base no objeto \texttt{dados}:
  \begin{compactenum}[(1)]
  \item Faça um histograma de CW
  \item Com base no histograma, construa uma hipótese para a média de CW
    \begin{compactenum}[(a)]
    \item Teste a igualdade dessa hipótese
    \item Teste uma desigualdade dessa hipótese
    \end{compactenum}
    Em ambos os casos use um nível de confiança de 90\%, e escreva uma
    frase com a sua conclusão.
  \item Faça um histograma de CW para cada sexo
  \item Com base nesses histogramas, construa uma hipótese para a
    diferença média de CW entre os sexos
    \begin{compactenum}[(a)]
    \item Teste a igualdade dessa hipótese
    \item Teste uma desigualdade dessa hipótese
    \end{compactenum}
    Em ambos os casos use um nível de confiança de 90\%, e escreva uma
    frase com a sua conclusão.
  \end{compactenum}
\end{frame}

\section{Regressão e correlação}

\begin{frame}[fragile=singleslide]{Regressão e correlação}
Vamos analisar a relação que existe entre CL e CW
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hlstd{(CW} \hlopt{~} \hlstd{CL,} \hlkwc{data} \hlstd{= dados)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=.6\textwidth]{figure/unnamed-chunk-28-1} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile]{Regressão e correlação}
  Um \textbf{modelo linear} entre duas variáveis $X$ e $Y$, é definido
  matematicamente como uma equação com dois parâmetros desconhecidos,
  \begin{equation*}
    Y = \beta_0 + \beta_1 X
  \end{equation*}
  A \textbf{análise de regressão} é a técnica estatística que analisa as
  relações existentes entre uma única variável \textbf{dependente}, e
  uma ou mais variáveis \textbf{independentes} \\~\\
  O objetivo é estudar as relações entre as variáveis, a partir de um
  \textbf{modelo matemático}, permitindo \textbf{estimar} o valor de uma
  variável a partir da outra
  \begin{itemize}
  \item Exemplo: sabendo a altura podemos determinar o peso de uma
    pessoa, se conhecemos os parâmetros do modelo anterior
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Regressão linear}
  O problema da análise de regressão consiste em definir a
  \textbf{forma} de relação existente entre as variáveis. \\~\\
  Por exemplo, podemos ter as seguintes relações
  \begin{align*}
    Y &= \beta_0 + \beta_1 X &\qquad \text{linear} \\
    Y &= \beta_0 X^{\beta_1} &\qquad \text{potência} \\
    Y &= \beta_0 e^{\beta_1 X} &\qquad \text{exponencial} \\
    Y &= \beta_0 + \beta_1 X + \beta_2 X^2 &\qquad \text{polinomial} \\
  \end{align*}
  Em todos os casos, a variável \textbf{dependente} é $Y$, aquela que
  será \textbf{predita} a partir da relação e da variável
  \textbf{independente} $X$
\end{frame}

\subsection{Regressão}

\begin{frame}[fragile]{Regressão linear}
  Em uma \textbf{análise de regressão linear} consideraremos apenas as
  variáveis que possuem uma \textbf{relação linear} entre si. \\~\\
  Uma análise de regressão linear \textbf{múltipla} pode associar $k$
  variáveis independentes ($X$) para ``explicar'' uma única variável
  dependente ($Y$),
  \begin{equation*}
    Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_k X_k + e
  \end{equation*}
  Uma análise de regressão linear \textbf{simples} associa uma única
  variável independente ($X$) com uma variável dependente ($Y$),
  \begin{equation*}
    Y = \beta_0 + \beta_1 X + e
  \end{equation*}
\end{frame}

\begin{frame}[fragile]{Regressão linear}
  Assim, dados $n$ pares de valores, $(X_1, Y_1), (X_2, Y_2), \ldots,
  (X_n, Y_n)$, se for admitido que $Y$ é função linear de $X$, pode-se
  estabelecer uma regressão linear simples, cujo modelo estatístico é
  \begin{equation*}
    Y_i = \beta_0 + \beta_1 X_i + e_i, \quad i = 1, 2, \ldots, n
  \end{equation*}
  onde:
  \begin{itemize}
  \item $Y$ é a variável \textbf{resposta} (ou \textbf{dependente})
  \item $X$ é a variável \textbf{explicativa} (ou \textbf{independente})
  \item $\beta_0$ é o \textbf{intercepto} da reta (valor de $Y$ quando
    $X = 0$)
    %% melhorar aqui: beta1 eh tg \alpha, onde \alpha eh o angulo
    %% ver se eh possivel calcular por trigonometria
  \item $\beta_1$ é o \textbf{coeficiente angular} da reta
    (\textbf{efeito} de $X$ sobre $Y$)
  \item $e_i \sim \text{N}(0, \sigma^2)$ é o \textbf{erro}, ou
    \textbf{desvio}, ou \textbf{resíduo}
  \end{itemize}
  O problema agora consiste em \textbf{estimar} os parâmetros $\beta_0$
  e $\beta_1$. \\~\\
\end{frame}

\begin{frame}[fragile]{Regressão linear}
  \textbf{Interpretação dos parâmetros:} \\~\\
  $\beta_0$ representa o ponto onde a reta corta o eixo $Y$ (na maioria
  das vezes não possui interpretação prática) \\~\\
  $\beta_1$ representa a variabilidade em $Y$ causada pelo aumento de
  uma unidade em $X$. Além disso,
  \begin{itemize}
  \item $\beta_1 > 0$ mostra que com o aumento de $X$, também há um
    aumento em $Y$
  \item $\beta_1 = 0$ mostra que \textbf{não há efeito} de $X$ sobre $Y$
  \item $\beta_1 < 0$ mostra que com a aumento de $X$, há uma diminuição
    em $Y$
  \end{itemize}
  %% tirei pq o beta1 eh muito grande, fica dificil interpretar
%% <<echo=FALSE, pdfcrop=TRUE, out.width=".7\\textwidth", fig.width=6,fig.height=5>>=
%% plot(peso ~ alt, xlab = "Altura (cm)", ylab = "Peso (kg)", pch = 19)
%% abline(m0)
%% beta0 <- round(coef(m0)[1], 2)
%% beta1 <- round(coef(m0)[2], 2)
%% text(x = 1.75, y = 60,
%%      labels = bquote(hat(Y) == .(beta0) + .(beta1) * X))
%% @
\end{frame}

\subsubsection[Estimação]{Estimação dos parâmetros}

\begin{frame}[fragile]{Estimação dos parâmetros}
  Como através de uma amostra obtemos uma estimativa da verdadeira
  equação de regressão, denominamos
  \begin{equation*}
    \hat{Y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_i
  \end{equation*}
  ou seja, $\hat{Y}_i$ é o valor \textbf{estimado} de $Y_i$, através
  das \textbf{estimativas} de $\beta_0$ e $\beta_1$, que chamaremos de
  $\hat{\beta}_0$ e $\hat{\beta}_1$. \\~\\
  Para cada valor de $Y_i$, temos um valor $\hat{Y}_i$ estimado pela
  equação de regressão,
  \begin{equation*}
    Y_i = \hat{Y}_i + e_i
  \end{equation*}
\end{frame}

\begin{frame}[fragile]{Estimação dos parâmetros}
  Portanto, o erro (ou desvio) de cada observação em relação ao modelo
  adotado será
  \begin{align*}
    e_i &= Y_i - \hat{Y}_i \\
    e_i &= Y_i - (\beta_0 + \beta_1 X_i)
  \end{align*}
  % lembre qe soh colca o chapeu quando iguala a zero depois
  Devemos então adotar um modelo cujos parâmetros $\beta_0$ e
  $\beta_1$, tornem esse diferença a menor possível. \\~\\
  Isso equivale a \textbf{minimizar} a \textbf{soma de quadrados dos
  resíduos} ($SQR$), ou do erro,
  \begin{equation*}
  SQR = \sum_{i=1}^{n} [Y_i - (\beta_0 + \beta_1 X_i)]^2
\end{equation*}
\end{frame}

\begin{frame}[fragile]{Estimação dos parâmetros}
  O método de minimizar a soma de quadrados dos resíduos é denominado de
  \textbf{método dos mínimos quadrados}. \\~\\
  Para se encontrar o ponto mínimo de uma função, temos que obter as
  derivadas parciais em relação a cada parâmetro,
  \begin{align*}
    \frac{\partial SQR}{\partial \beta_0} &= 2 \sum_{i=1}^{n} [Y_i -
    \beta_0 - \beta_1 X_i] (-1) \\
    \frac{\partial SQR}{\partial \beta_1} &= 2 \sum_{i=1}^{n} [Y_i -
    \beta_0 - \beta_1 X_i] (-X_i)
  \end{align*}
  e igualar os resultados a zero
  \begin{equation*}
    \hat{\beta}_0 = \frac{\partial SQR}{\partial \beta_0} = 0 \qquad
    \text{e} \qquad
    \hat{\beta}_1 = \frac{\partial SQR}{\partial \beta_1} = 0
  \end{equation*}
\end{frame}

\begin{frame}[fragile]{Estimação dos parâmetros}
  Dessa forma, chegamos às \textbf{estimativas de mínimos quadrados}
  para os parâmetros $\beta_0$ e $\beta_1$:
  \begin{align*}
    \hat{\beta}_1 &= \frac{\sum_{i=1}^{n} X_iY_i - \frac{\sum_{i=1}^{n}
        X_i \sum_{i=1}^{n} Y_i}{n}}{\sum_{i=1}^{n}X_i^2 -
      \frac{(\sum_{i=1}^{n} X_i)^2}{n}} \\
    & \\
    \hat{\beta_0} &= \bar{Y} - \hat{\beta}_1 \bar{X}
  \end{align*}
  onde
  \begin{align*}
    \bar{Y} = \frac{1}{n} \sum_{i=1}^{n} Y_i \qquad \text{e} \qquad
    \bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i
  \end{align*}
\end{frame}

\begin{frame}[fragile=singleslide]{Regressão}
Ajustando um modelo linear no \R
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mod} \hlkwb{<-} \hlkwd{lm}\hlstd{(CW} \hlopt{~} \hlstd{CL,} \hlkwc{data} \hlstd{= dados)}
\hlstd{mod}
\end{alltt}
\begin{verbatim}

Call:
lm(formula = CW ~ CL, data = dados)

Coefficients:
(Intercept)           CL  
      1.187        1.097  
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Regressão}{Sumário}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(mod)}
\end{alltt}
\begin{verbatim}

Call:
lm(formula = CW ~ CL, data = dados)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.7762 -0.5699  0.1098  0.4629  1.8273 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 1.186950   0.285340    4.16 5.28e-05 ***
CL          1.097451   0.008698  126.17  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.7827 on 154 degrees of freedom
Multiple R-squared:  0.9904,	Adjusted R-squared:  0.9904 
F-statistic: 1.592e+04 on 1 and 154 DF,  p-value: < 2.2e-16
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Regressão}{Tabela de Análise de Variância}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{anova}\hlstd{(mod)}
\end{alltt}
\begin{verbatim}
Analysis of Variance Table

Response: CW
           Df Sum Sq Mean Sq F value    Pr(>F)    
CL          1 9752.6  9752.6   15919 < 2.2e-16 ***
Residuals 154   94.3     0.6                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Regressão}{Ajuste gráfico}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hlstd{(CW} \hlopt{~} \hlstd{CL,} \hlkwc{data} \hlstd{= dados)}
\hlkwd{abline}\hlstd{(mod)}
\hlkwd{plot}\hlstd{(CW} \hlopt{~} \hlstd{CL,} \hlkwc{data} \hlstd{= dados,} \hlkwc{xlim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{50}\hlstd{),} \hlkwc{ylim} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{55}\hlstd{))}
\hlkwd{abline}\hlstd{(mod)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=.49\textwidth]{figure/unnamed-chunk-32-1} 
\includegraphics[width=.49\textwidth]{figure/unnamed-chunk-32-2} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Regressão}{Análise dos resíduos}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{par}\hlstd{(}\hlkwc{mfrow} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{2}\hlstd{,}\hlnum{2}\hlstd{))}
\hlkwd{plot}\hlstd{(mod)}
\hlkwd{par}\hlstd{(}\hlkwc{mfrow} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,}\hlnum{1}\hlstd{))}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=.6\textwidth]{figure/unnamed-chunk-33-1} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Regressão}
Acessando os componentes do objeto \texttt{mod}:
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{names}\hlstd{(mod)}
\end{alltt}
\begin{verbatim}
 [1] "coefficients"  "residuals"     "effects"      
 [4] "rank"          "fitted.values" "assign"       
 [7] "qr"            "df.residual"   "xlevels"      
[10] "call"          "terms"         "model"        
\end{verbatim}
\begin{alltt}
\hlkwd{names}\hlstd{(}\hlkwd{summary}\hlstd{(mod))}
\end{alltt}
\begin{verbatim}
 [1] "call"          "terms"         "residuals"    
 [4] "coefficients"  "aliased"       "sigma"        
 [7] "df"            "r.squared"     "adj.r.squared"
[10] "fstatistic"    "cov.unscaled" 
\end{verbatim}
\begin{alltt}
\hlkwd{names}\hlstd{(}\hlkwd{anova}\hlstd{(mod))}
\end{alltt}
\begin{verbatim}
[1] "Df"      "Sum Sq"  "Mean Sq" "F value" "Pr(>F)" 
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Regressão}
  Veja que o \texttt{Residual standard error: 0.7827} é o estimador do
  desvio-padrão residual $\hat{\sigma}^{2}_{e} = \frac{\text{SQRes}}{n-2}$,
  ou seja,
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{sqrt}\hlstd{(}\hlkwd{anova}\hlstd{(mod)}\hlopt{$}\hlstd{Sum[}\hlnum{2}\hlstd{]}\hlopt{/}\hlkwd{anova}\hlstd{(mod)}\hlopt{$}\hlstd{Df[}\hlnum{2}\hlstd{])}
\end{alltt}
\begin{verbatim}
[1] 0.7827079
\end{verbatim}
\end{kframe}
\end{knitrout}
e que \texttt{F-statistic: 1.592e+04} (15920) é o mesmo valor de
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{anova}\hlstd{(mod)}\hlopt{$}\hlstd{F[}\hlnum{1}\hlstd{]}
\end{alltt}
\begin{verbatim}
[1] 15919.11
\end{verbatim}
\end{kframe}
\end{knitrout}
que testa a mesma hipótese da ANOVA. De fato, o valor de $t^2$ para
$\beta_1$ no sumário do modelo é
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(mod)}\hlopt{$}\hlstd{coef[}\hlnum{2}\hlstd{,}\hlnum{3}\hlstd{]}\hlopt{^}\hlnum{2}
\end{alltt}
\begin{verbatim}
[1] 15919.11
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\subsection{Correlação}

\begin{frame}[fragile]{Correlação}
  Até agora o interesse estava em estudar qual a influência de uma
  V.A. $X$ sobre uma V.A. $Y$, por meio de uma \textbf{relação linear}. \\~\\
  Assim, em uma análise de regressão é indispensável identificar qual
  variável é dependente. \\~\\
  Na \textbf{análise de correlação} isto não é necessário, pois queremos
  estudar o \textbf{grau de relacionamento} entre as variáveis $X$ e
  $Y$, ou seja, uma medida de \textbf{covariabilidade} entre elas. \\~\\
  A correlação é considerada como uma medida de \textbf{influência
    mútua} entre variáveis, por isso não é necessário especificar quem
  influencia e quem é influenciado.
\end{frame}

\begin{frame}[fragile]{Correlação}
  O \textbf{grau de relação} entre duas variáveis pode ser medido
  através do \textbf{coeficiente de correlação linear} ($r$), dado por
  \begin{equation*}
    r = \frac{\sum_{i=1}^{n} X_iY_i - \frac{\sum_{i=1}^{n}
        X_i \sum_{i=1}^{n} Y_i}{n}}{\sqrt{\sum_{i=1}^{n}X_i^2 -
      \frac{(\sum_{i=1}^{n} X_i)^2}{n}} \cdot \sqrt{\sum_{i=1}^{n}Y_i^2 -
      \frac{(\sum_{i=1}^{n} Y_i)^2}{n}}}
  \end{equation*}
  onde
  \begin{equation*}
    -1 \leq r \leq 1
  \end{equation*}
  Portanto,
  \begin{itemize}
  \item $r=1$ correlação \textbf{positiva} perfeita entre as variáveis
  \item $r=0$ \textbf{não há} correlação entre as variáveis
  \item $r= -1$ correlação \textbf{negativa} perfeita entre as variáveis
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{Correlação}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=.33\textwidth]{figure/unnamed-chunk-38-1} 
\includegraphics[width=.33\textwidth]{figure/unnamed-chunk-38-2} 
\includegraphics[width=.33\textwidth]{figure/unnamed-chunk-38-3} 

}



\end{knitrout}
\end{frame}

%% Exemplos de que correlacao nao implica em causação

\begin{frame}[fragile]{Correlação}
  O \textbf{coeficiente de determinação} ($r^2$) é o quadrado do
  coeficiente de correlação, por consequência
  \begin{equation*}
    0 \leq r^2 \leq 1
  \end{equation*}
  O $r^2$ nos dá a \textbf{porcentagem de variação em $Y$ que pode ser explicada
  pela variável independente $X$}. \\~\\
  Quanto mais próximo de 1, maior é a explicação da variável $Y$ pela
  variável $X$.
\end{frame}

\begin{frame}[fragile]{Correlação}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/unnamed-chunk-39-1} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Exercícios}
Com as colunas BD e CL do objeto \texttt{dados}
\begin{compactenum}[(1)]
\item Faça um gráfico da relação entre estas variáveis
\item Faça um teste de correlação
\item Ajuste um modelo linear
  \begin{compactenum}[(a)]
  \item Veja o sumário
  \item Ajuste a linha do modelo no gráfico
  \item Verifique os resíduos
  \end{compactenum}
\end{compactenum}
Qual sua conclusão?
\small
\begin{itemize}
\item Existe correlação significativa? De que tipo (positiva, negativa)?
\item O modelo linear descreve bem a relação entre estas duas variáveis
  (verifique com o valor de \verb+Pr(>|t|)+ e do $R^2$)
\item O modelos foi bem ajustado aos dados (observe os resíduos)
\end{itemize}
\end{frame}


\section[ANOVA]{Análise de Variância}

%\begin{frame}[fragile=singleslide]{Análise de Variância}{Base de dados}
%<<>>=
%## dados <- read.table("crabs.csv", header = T, sep = ";",
%##                     dec = ",")
%## str(dados)
%@
%\end{frame}

\begin{frame}[fragile=singleslide]{Análise de Variância}
Definição: $y_{ij}$ representa a observação $j$ do grupo $i$;
$\bar{y}_{i}$ é a média do grupo $i$; $\bar{y}$ é a média geral de todas
as observações. As observações podem ser decompostas em
\begin{equation*}
  y_{ij} = \quad \bar{y} \quad + \quad (\bar{y}_{i} - \bar{y}) \quad + \quad
  (y_{ij} - \bar{y}_{i})
\end{equation*}
que corresponde ao modelo
\begin{equation*}
  y_{ij} = \quad \theta \quad + \quad \mu_i \quad + \quad \epsilon_{ij},
  \qquad \epsilon_{ij} \sim N(0, \sigma^2)
\end{equation*}
A hipótese a ser testada de que todos os grupos são iguais (\textit{i.e}
médias iguais) implica que todos os $\mu_{i}$ são iguais:
\begin{align*}
  &H_0: \mu_1 = \mu_2 = \cdots = \mu_n \\
  &H_1: \textsf{pelo menos um}\ \mu_i\ \textsf{é diferente dos demais}
\end{align*}
\end{frame}

\begin{frame}[fragile=singleslide]{Análise de Variância}
Voltando ao exemplo da diferença de CL entre as duas espécies:\\
$\bar{y}_A = 29.87$ e
$\bar{y}_L = 34.08$
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{with}\hlstd{(dados,} \hlkwd{tapply}\hlstd{(CL, especie, summary))}
\end{alltt}
\begin{verbatim}
$azul
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  14.70   24.60   30.10   29.87   34.50   47.10 

$laranja
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  16.70   29.40   34.50   34.08   39.25   47.60 
\end{verbatim}
\end{kframe}
\end{knitrout}
Média geral $\bar{y} = 32$
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{mean}\hlstd{(dados}\hlopt{$}\hlstd{CL)}
\end{alltt}
\begin{verbatim}
[1] 32.00385
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Análise de Variância}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{boxplot}\hlstd{(CL} \hlopt{~} \hlstd{especie,} \hlkwc{data} \hlstd{= dados)}
\hlkwd{abline}\hlstd{(}\hlkwc{h} \hlstd{=} \hlkwd{mean}\hlstd{(dados}\hlopt{$}\hlstd{CL),} \hlkwc{lty} \hlstd{=} \hlnum{2}\hlstd{,} \hlkwc{col} \hlstd{=} \hlstr{"red"}\hlstd{,} \hlkwc{lwd} \hlstd{=} \hlnum{2}\hlstd{)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=.6\textwidth]{figure/unnamed-chunk-42-1} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Análise de Variância}
Geometricamente
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=.7\textwidth]{figure/unnamed-chunk-43-1} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Análise de Variância}
Podemos ajustar um modelo linear entre CL e espécie
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mod} \hlkwb{<-} \hlkwd{lm}\hlstd{(CL} \hlopt{~} \hlstd{especie,} \hlkwc{data} \hlstd{= dados)}
\hlkwd{summary}\hlstd{(mod)}
\end{alltt}
\begin{verbatim}

Call:
lm(formula = CL ~ especie, data = dados)

Residuals:
     Min       1Q   Median       3Q      Max 
-17.3848  -5.0188   0.2732   5.0192  17.2312 

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)     29.8688     0.7902  37.799  < 2e-16 ***
especielaranja   4.2160     1.1104   3.797  0.00021 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.934 on 154 degrees of freedom
Multiple R-squared:  0.08559,	Adjusted R-squared:  0.07966 
F-statistic: 14.42 on 1 and 154 DF,  p-value: 0.0002104
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Análise de Variância}
Ajustando o modelo
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=.7\textwidth]{figure/unnamed-chunk-45-1} 

}



\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Análise de Variância}
Você lembra do teste-t feito anteriormente?
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{teste} \hlkwb{<-} \hlkwd{t.test}\hlstd{(CL} \hlopt{~} \hlstd{especie,} \hlkwc{data} \hlstd{= dados,} \hlkwc{mu} \hlstd{=} \hlnum{0}\hlstd{,}
                \hlkwc{alternative} \hlstd{=} \hlstr{"two.sided"}\hlstd{,} \hlkwc{conf.level} \hlstd{=} \hlnum{0.95}\hlstd{)}
\hlstd{teste}
\end{alltt}
\begin{verbatim}

	Welch Two Sample t-test

data:  CL by especie
t = -3.7935, df = 152.732, p-value = 0.0002135
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -6.411592 -2.020366
sample estimates:
   mean in group azul mean in group laranja 
             29.86883              34.08481 
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Análise de Variância}
Notou a relação?
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(mod)}\hlopt{$}\hlstd{coefficients}
\end{alltt}
\begin{verbatim}
                Estimate Std. Error  t value     Pr(>|t|)
(Intercept)    29.868831  0.7902012 37.79902 8.192364e-80
especielaranja  4.215979  1.1104178  3.79675 2.104221e-04
\end{verbatim}
\begin{alltt}
\hlstd{teste}\hlopt{$}\hlstd{p.value}
\end{alltt}
\begin{verbatim}
[1] 2.135202e-04
\end{verbatim}
\begin{alltt}
\hlstd{teste}\hlopt{$}\hlstd{estimate}
\end{alltt}
\begin{verbatim}
   mean in group azul mean in group laranja 
             29.86883              34.08481 
\end{verbatim}
\begin{alltt}
\hlkwd{diff}\hlstd{(teste}\hlopt{$}\hlstd{estimate)}
\end{alltt}
\begin{verbatim}
mean in group laranja 
             4.215979 
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Análise de Variância}
A ANOVA vai testar apenas a hipótese inicial
\begin{align*}
  &H_0: \mu_A = \mu_L \\
  &H_1: \mu_A \neq \mu_L
\end{align*}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{anova}\hlstd{(mod)}
\end{alltt}
\begin{verbatim}
Analysis of Variance Table

Response: CL
           Df Sum Sq Mean Sq F value    Pr(>F)    
especie     1  693.1  693.09  14.415 0.0002104 ***
Residuals 154 7404.3   48.08                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}
\end{kframe}
\end{knitrout}
Aqui a única conclusão é de que os $\mu_i$ não são iguais (mas você
não sabe quanto e nem quais!)
\end{frame}

\begin{frame}[fragile=singleslide]{Análise de Variância}
Se olharmos apenas o resultado da ANOVA, podemos prosseguir com a
análise fazendo um teste \textit{a posteriori} para verificarmos quais
são os grupos que diferem entre si. Um deles é o teste de Tukey
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mod.anova} \hlkwb{<-} \hlkwd{aov}\hlstd{(CL} \hlopt{~} \hlstd{especie,} \hlkwc{data} \hlstd{= dados)}
\hlkwd{TukeyHSD}\hlstd{(mod.anova)}
\end{alltt}
\begin{verbatim}
  Tukey multiple comparisons of means
    95% family-wise confidence level

Fit: aov(formula = CL ~ especie, data = dados)

$especie
                 diff      lwr      upr     p adj
laranja-azul 4.215979 2.022362 6.409596 0.0002104
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Análise de Variância}
Porque então fazer uma ANOVA???
\begin{itemize}
\item Quando formos comparar a média de mais de 2 grupos
\item Não é possível fazer um teste-t para mais de 2 grupos
\item Por exemplo, com 3 grupos (A, B, C) teríamos que fazer 3
  comparações (A:B, A:C, B:C)
  \begin{itemize}
  \item Com um nível de confiança de 95\% ($\alpha = 0.05$)
    para cada teste, os 3 testes teriam um nível de confiança
    $(1-\alpha)^3$
  \item Portanto $(1-0.05)^3 = (0.95)^3 = 0.85$
  \item Isso implica que quanto mais comparações forem feitas, menor
    será seu nível de confiança no resultado dos testes.
  \end{itemize}
\end{itemize}
\end{frame}

\section[MLGs]{Modelos Lineares Generalizados}

\begin{frame}[fragile=singleslide]{Modelos Lineares Generalizados}
Nelder e Wedderburn (1972) mostraram que uma série de técnicas
estatísticas podem ser formuladas de forma unificada, como uma classe de
modelos de regressão. A essa teoria, uma extensão dos modelos clássicos
de regressão, deram o nome de \textbf{Modelos Lineares
  Generalizados}.
\begin{center}
  Teste-t $\subset$ ANOVA $\subset$ ANCOVA* $\subset$ ML $\subset$
  ML-MULT* $\subset$ MLG
\end{center}
  \begin{itemize}
  \item Teste-t: compara uma ou duas médias
  \item ANOVA: compara 2 ou mais médias (fator)
  \item ANCOVA: compara 2 ou mais médias (fator) + variáveis numéricas
  \item ML: regressão de $y$ (numérico) em função de um único $x$
    (numérico ou fator)
  \item ML-MULT: regressão de $y$ (numérico) em função de mais de um $x$
    (numéricos ou fatores)
  \item MLG: Similar ao ML-MULT, mas extende o modelo para que $y$ possa
    ser um fator ou ter uma distribuição diferente da normal.
  \end{itemize}
\end{frame}

\begin{frame}[fragile=singleslide]{Modelos Lineares Generalizados}
Os MLGs são formados por três componentes:
\begin{compactenum}
\item \textbf{Componente aleatório}: a variável resposta do modelo, com
  distribuição pertencente à família de distribuições exponencial.
\item \textbf{Componente sistemático}: as variáveis explicativas, que
  entram na forma de uma estrutura linear.
\item \textbf{Função de ligação}: função que liga os componentes
  aleatório e sistemático.
\end{compactenum}
\end{frame}

\begin{frame}[fragile=singleslide]{Modelos Lineares Generalizados}
De maneira geral, os MLGs descrevem a relação entre a variável resposta
$y_i$ ($i = 1, \ldots, n$) através de preditores $x_i$. A média de $y_i$
condicionada aos preditores $x_i$ é
\begin{equation*}
  E(y_i|x_i) = \mu_i
\end{equation*}
e existe uma transformação de $\mu_i$ de forma que
\begin{equation*}
  g(\mu_i) = x_{i}^{T}\beta
\end{equation*}
onde $g(\cdot)$ é uma função de ligação conhecida, e $\beta$ é o vetor
de parâmetros a ser estimado.
\end{frame}

\begin{frame}[fragile=singleslide]{Modelos Lineares Generalizados}
Distribuições da família exponencial e funções de ligação (P = link
padrão)
\begin{center}
\begin{table}[h!]
\renewcommand{\baselinestretch}{1}
\small\footnotesize\scriptsize
\begin{tabular}{lcccccc}
\hline
Link & \texttt{binomial} & \texttt{poisson} & \texttt{negative} &
\texttt{Gamma} & \texttt{gaussian} & \texttt{inverse}\\
    &       &    & \texttt{binomial} &  &  & \texttt{gaussian} \\
\hline
\texttt{logit} & P & & & & & \\
\texttt{probit} & $\bullet$ & & & & &  \\
\texttt{cloglog} & $\bullet$ & & & & &  \\
\texttt{identity} &  & $\bullet$ & $\bullet$ & $\bullet$ & P &  \\
\texttt{inverse} &  & & & P & &  \\
\texttt{log} &  & P & P & $\bullet$ & &  \\
\verb|1/mu^2| & & & & & & P  \\
\texttt{sqrt} & & $\bullet$ & $\bullet$ & & &  \\
\hline
\end{tabular}
\end{table}
\end{center}
\end{frame}

\begin{frame}[fragile=singleslide]{Modelos Lineares Generalizados}
Para ajustar um MLG usamos a função \texttt{glm()}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mod.glm} \hlkwb{<-} \hlkwd{glm}\hlstd{(CL} \hlopt{~} \hlstd{especie,} \hlkwc{data} \hlstd{= dados,}
               \hlkwc{family} \hlstd{=} \hlkwd{gaussian}\hlstd{(}\hlkwc{link} \hlstd{=} \hlstr{"identity"}\hlstd{))}
\hlkwd{summary}\hlstd{(mod.glm)}
\end{alltt}
\begin{verbatim}

Call:
glm(formula = CL ~ especie, family = gaussian(link = "identity"), 
    data = dados)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-17.3848   -5.0188    0.2732    5.0192   17.2312  

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)     29.8688     0.7902  37.799  < 2e-16 ***
especielaranja   4.2160     1.1104   3.797  0.00021 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for gaussian family taken to be 48.08018)

    Null deviance: 8097.4  on 155  degrees of freedom
Residual deviance: 7404.3  on 154  degrees of freedom
AIC: 1050.9

Number of Fisher Scoring iterations: 2
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}

\begin{frame}[fragile=singleslide]{Modelos Lineares Generalizados}
Quando existe mais de uma variável resposta ($y$)? \textbf{Métodos
  multivariados}!
\end{frame}

\begin{frame}[fragile=singleslide]{Exercícios}
Com o objeto \texttt{dados}
\begin{compactenum}[(1)]
\item Faça um boxplot de CW por sexo
\item Faça um teste-t para testar se existe diferença entre as médias de
  CW para machos e fêmeas
\item Ajuste um modelo linear para testar essa mesma hipótese
\item Faça uma ANOVA e o teste de Tukey
\end{compactenum}
Qual sua conclusão?
\end{frame}

\end{document}
